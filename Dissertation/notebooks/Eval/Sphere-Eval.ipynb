{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "\n",
    "from Eval.Mesh import CreatePointcloudFromDir\n",
    "from Eval.Clouds.Sphere import CreateBaseSpherePointCloud\n",
    "from Eval.Error import CalculateRMSE, CalculateSTD\n",
    "from Eval.Plotting import get_histogram_standards\n",
    "from Utils.Viz import VizualiseBaseTargetPointclouds\n",
    "from Utils.Format import MilimeterToMeter, MeterToMilimeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Base Clouds for Comparison, Created Programatically for High Accuracy.\n",
    "\n",
    "# Diameter of Base IRL Sphere: 200mm\n",
    "baseSphere = CreateBaseSpherePointCloud(diameter = MilimeterToMeter(200), resolution=5000)\n",
    "baseSphere.paint_uniform_color([1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current Technique and Data in Review\n",
    "\n",
    "eval = 'Point_E' # Either Kinect, PolyCam or Point_E\n",
    "\n",
    "evalDataDir = f'../data/{eval}/sphere.ply'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Obtained Data Clouds for Comparison, on the Base Programatically Created Clouds.\n",
    "\n",
    "collectedSphere = CreatePointcloudFromDir(evalDataDir)\n",
    "collectedSphere.paint_uniform_color([1.0, 0.0, 0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Data Adjustment based on know problems with Each technique.\n",
    "\n",
    "match eval:\n",
    "    case 'Kinect':\n",
    "        print(\"Performing Kinect Data Adjustment\")\n",
    "        collectedSphere = collectedSphere.uniform_down_sample(every_k_points=5)\n",
    "    \n",
    "    case 'PolyCam':\n",
    "        print(\"Performing PolyCam Data Adjustment\")\n",
    "        collectedSphere = collectedSphere.uniform_down_sample(every_k_points=10)\n",
    "\n",
    "    case 'Point_E':\n",
    "        print(\"Performing Point_E Data Adjustment\")\n",
    "\n",
    "        print(\"Scaling Point_E Data to Match Meter Units\")\n",
    "        collectedSphere.scale(MilimeterToMeter(200), collectedSphere.get_center())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform ICP Registration to Obtain a Transformation Matrix\n",
    "# This allows for more accurate comparison of the clouds, by making them similar positioning.\n",
    "\n",
    "\n",
    "icpRegResults = o3d.pipelines.registration.registration_icp(collectedSphere, \n",
    "                                                            baseSphere, \n",
    "                                                            0.1, \n",
    "                                                            np.identity(4), \n",
    "                                                            o3d.pipelines.registration.TransformationEstimationPointToPoint(), \n",
    "                                                            o3d.pipelines.registration.ICPConvergenceCriteria(max_iteration=1000))\n",
    "\n",
    "print(icpRegResults)\n",
    "\n",
    "# Apply the Transformation Matrix to the Obtained Data Clouds\n",
    "collectedSphere.transform(icpRegResults.transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick Visualization of both the Obtained Cloud and the Base Cloud.\n",
    "\n",
    "VizualiseBaseTargetPointclouds(baseSphere, collectedSphere)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the RMSE between the two clouds.\n",
    "\n",
    "rmse = CalculateRMSE(collectedSphere, baseSphere)\n",
    "\n",
    "# Convert to mm\n",
    "rmse *= 1000\n",
    "\n",
    "print(f'RMSE (mm): {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the STD between the two clouds.\n",
    "\n",
    "stdData = CalculateSTD(collectedSphere, baseSphere)\n",
    "\n",
    "print(f'STD (m): {stdData}')\n",
    "\n",
    "# Convert to mm\n",
    "stdData[\"std\"] *= 1000\n",
    "stdData[\"mean\"] *= 1000\n",
    "\n",
    "stdData[\"min\"] *= 1000\n",
    "stdData[\"max\"] *= 1000\n",
    "##\n",
    "\n",
    "print(f'STD (mm): {stdData}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Histogram Standards\n",
    "\n",
    "max_density, max_dist = get_histogram_standards(collectedSphere, baseSphere)\n",
    "\n",
    "print (f'Max Prob Density: {max_density}, Max Dist: {max_dist}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils.Data import JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsejsonDir = \"../data/techniques-rmse-data.json\"\n",
    "stdjsonDir = \"../data/techniques-std-data.json\"\n",
    "\n",
    "rmse_data = JSON(rmsejsonDir)\n",
    "std_data = JSON(stdjsonDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update Stored RMSE Data\n",
    "\n",
    "rmse_data.data[eval][\"Sphere\"].update({\n",
    "    \"rmse\": rmse,\n",
    "    \"inlier_rmse\": MeterToMilimeter(icpRegResults.inlier_rmse)\n",
    "})\n",
    "\n",
    "rmse_data.print()\n",
    "rmse_data.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update Stored STD Data\n",
    "std_data.data[eval][\"Sphere\"].update(stdData)\n",
    "\n",
    "# Update Stored STD Standards\n",
    "histStandards = std_data.data[\"STANDARDS\"]\n",
    "\n",
    "if (max_density > histStandards[\"MAX_PROB_DENSITY\"]):\n",
    "    histStandards[\"MAX_PROB_DENSITY\"] = float(max_density)\n",
    "    print(f\"New Max Prob Density: {max_density}\")\n",
    "\n",
    "if (max_dist > histStandards[\"MAX_DISTANCE\"]):\n",
    "    histStandards[\"MAX_DISTANCE\"] = float(max_dist)\n",
    "    print(f\"New Max Distance: {max_dist}\")\n",
    "\n",
    "std_data.data[\"STANDARDS\"].update(histStandards)\n",
    "\n",
    "# Set the Max Frequency\n",
    "std_data.print()\n",
    "std_data.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fa3b4bcd30999d4dd3b7790820c45ccaef78365348c8c252963eb6d102622af6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
